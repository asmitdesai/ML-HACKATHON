{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d388375",
   "metadata": {},
   "source": [
    "# Intelligent Hangman AI Agent\n",
    "\n",
    "This notebook implements an intelligent Hangman game-playing agent using a hybrid approach combining Hidden Markov Models (HMM) and Reinforcement Learning (RL). The agent learns to make strategic decisions by combining probabilistic modeling with reinforcement learning to maximize success rate while minimizing wrong guesses.\n",
    "\n",
    "## Project Overview:\n",
    "1. Train an HMM on a 50,000-word corpus to model letter probabilities\n",
    "2. Implement a Hangman game environment\n",
    "3. Create an RL agent using Deep Q-Learning\n",
    "4. Train and evaluate the agent's performance\n",
    "\n",
    "## Evaluation Criteria:\n",
    "Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f107a",
   "metadata": {},
   "source": [
    "# 1. Environment Setup and Data Loading\n",
    "\n",
    "Let's start by importing the required libraries and setting up our development environment. We'll also load and preprocess our corpus of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1ed2bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/asmitdesai/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN2at23SavedTensorDefaultHooks7disableERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb\n  Referenced from: <EEC6536B-B355-3AC8-9ED6-3D15D73F5BF6> /Users/asmitdesai/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_python.dylib\n  Expected in:     <616791F0-29C3-3F88-8A88-D072E7E40979> /Users/asmitdesai/anaconda3/lib/libtorch_cpu.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:367\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    366\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSymInt\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/asmitdesai/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN2at23SavedTensorDefaultHooks7disableERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb\n  Referenced from: <EEC6536B-B355-3AC8-9ED6-3D15D73F5BF6> /Users/asmitdesai/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_python.dylib\n  Expected in:     <616791F0-29C3-3F88-8A88-D072E7E40979> /Users/asmitdesai/anaconda3/lib/libtorch_cpu.dylib"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Constants\n",
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
    "MAX_WRONG_GUESSES = 6\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find corpus file at corpus.txt\n",
      "Loaded 0 words from corpus\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess the corpus\n",
    "def load_corpus(file_path: str = 'corpus.txt') -> List[str]:\n",
    "    \"\"\"\n",
    "    Load words from the corpus file and preprocess them\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            words = [word.strip().lower() for word in f.readlines()]\n",
    "        return [word for word in words if all(c in ALPHABET for c in word)]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find corpus file at {file_path}\")\n",
    "        return []\n",
    "\n",
    "# Utility functions for word processing\n",
    "def mask_word(word: str, guessed_letters: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    Return the word with unguessed letters masked as underscores\n",
    "    \"\"\"\n",
    "    return ''.join(letter if letter in guessed_letters else '_' for letter in word)\n",
    "\n",
    "def get_word_length_distribution(words: List[str]) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Get distribution of word lengths in the corpus\n",
    "    \"\"\"\n",
    "    return Counter(len(word) for word in words)\n",
    "\n",
    "# Load the corpus\n",
    "corpus = load_corpus()\n",
    "print(f\"Loaded {len(corpus)} words from corpus\")\n",
    "\n",
    "# Analyze word length distribution\n",
    "length_dist = get_word_length_distribution(corpus)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(length_dist.keys(), length_dist.values())\n",
    "plt.title('Word Length Distribution in Corpus')\n",
    "plt.xlabel('Word Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4c4f7",
   "metadata": {},
   "source": [
    "# 2. Hidden Markov Model Implementation\n",
    "\n",
    "Now we'll implement the Hidden Markov Model (HMM) that will serve as our agent's \"intuition\". The HMM will help us model the probability of letters appearing in different positions of words.\n",
    "\n",
    "Our HMM implementation will include:\n",
    "1. State transitions (letter-to-letter probabilities)\n",
    "2. Emission probabilities (letter probabilities in different positions)\n",
    "3. Forward-backward algorithm for probability calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanHMM:\n",
    "    def __init__(self, n_states: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize HMM for Hangman word prediction\n",
    "        \n",
    "        Args:\n",
    "            n_states: Number of hidden states in the HMM\n",
    "        \"\"\"\n",
    "        self.n_states = n_states\n",
    "        self.n_emissions = len(ALPHABET)\n",
    "        self.letter_to_idx = {letter: idx for idx, letter in enumerate(ALPHABET)}\n",
    "        \n",
    "        # Initialize model parameters\n",
    "        self.transition_probs = np.ones((n_states, n_states)) / n_states\n",
    "        self.emission_probs = np.ones((n_states, self.n_emissions)) / self.n_emissions\n",
    "        self.initial_probs = np.ones(n_states) / n_states\n",
    "        \n",
    "    def _prepare_sequence(self, word: str) -> np.ndarray:\n",
    "        \"\"\"Convert word to sequence of emission indices\"\"\"\n",
    "        return np.array([self.letter_to_idx[c] for c in word])\n",
    "    \n",
    "    def forward_algorithm(self, emissions: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute forward probabilities for an emission sequence\n",
    "        \"\"\"\n",
    "        T = len(emissions)\n",
    "        alpha = np.zeros((T, self.n_states))\n",
    "        \n",
    "        # Initialize first timestep\n",
    "        alpha[0] = self.initial_probs * self.emission_probs[:, emissions[0]]\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(1, T):\n",
    "            for s in range(self.n_states):\n",
    "                alpha[t, s] = self.emission_probs[s, emissions[t]] * np.sum(\n",
    "                    alpha[t-1] * self.transition_probs[:, s])\n",
    "                \n",
    "        return alpha\n",
    "    \n",
    "    def backward_algorithm(self, emissions: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute backward probabilities for an emission sequence\n",
    "        \"\"\"\n",
    "        T = len(emissions)\n",
    "        beta = np.zeros((T, self.n_states))\n",
    "        \n",
    "        # Initialize last timestep\n",
    "        beta[-1] = 1\n",
    "        \n",
    "        # Backward pass\n",
    "        for t in range(T-2, -1, -1):\n",
    "            for s in range(self.n_states):\n",
    "                beta[t, s] = np.sum(\n",
    "                    beta[t+1] * self.transition_probs[s, :] * \n",
    "                    self.emission_probs[:, emissions[t+1]])\n",
    "                \n",
    "        return beta\n",
    "    \n",
    "    def train(self, words: List[str], n_iterations: int = 100):\n",
    "        \"\"\"\n",
    "        Train HMM using Baum-Welch algorithm\n",
    "        \"\"\"\n",
    "        for _ in tqdm(range(n_iterations), desc=\"Training HMM\"):\n",
    "            trans_counts = np.zeros_like(self.transition_probs)\n",
    "            emit_counts = np.zeros_like(self.emission_probs)\n",
    "            init_counts = np.zeros_like(self.initial_probs)\n",
    "            \n",
    "            # E-step\n",
    "            for word in words:\n",
    "                emissions = self._prepare_sequence(word)\n",
    "                T = len(emissions)\n",
    "                \n",
    "                alpha = self.forward_algorithm(emissions)\n",
    "                beta = self.backward_algorithm(emissions)\n",
    "                \n",
    "                # Compute posteriors\n",
    "                gamma = alpha * beta\n",
    "                gamma /= gamma.sum(axis=1, keepdims=True)\n",
    "                \n",
    "                # Update counts\n",
    "                init_counts += gamma[0]\n",
    "                for t in range(T-1):\n",
    "                    trans_counts += np.outer(gamma[t], gamma[t+1])\n",
    "                for t in range(T):\n",
    "                    emit_counts[:, emissions[t]] += gamma[t]\n",
    "            \n",
    "            # M-step\n",
    "            self.initial_probs = init_counts / init_counts.sum()\n",
    "            self.transition_probs = trans_counts / trans_counts.sum(axis=1, keepdims=True)\n",
    "            self.emission_probs = emit_counts / emit_counts.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def get_letter_probabilities(self, partial_word: str, guessed_letters: Set[str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Get probability distribution over next possible letters\n",
    "        \"\"\"\n",
    "        # Convert partial word to emissions with masked positions\n",
    "        emissions = []\n",
    "        for c in partial_word:\n",
    "            if c == '_':\n",
    "                emissions.append(-1)  # Special value for masked positions\n",
    "            else:\n",
    "                emissions.append(self.letter_to_idx[c])\n",
    "        emissions = np.array(emissions)\n",
    "        \n",
    "        # Get probabilities for masked positions\n",
    "        probs = defaultdict(float)\n",
    "        for pos in range(len(partial_word)):\n",
    "            if emissions[pos] == -1:\n",
    "                alpha = self.forward_algorithm(emissions[:pos])\n",
    "                beta = self.backward_algorithm(emissions[pos+1:])\n",
    "                \n",
    "                # Compute distribution over possible letters\n",
    "                for letter in ALPHABET:\n",
    "                    if letter not in guessed_letters:\n",
    "                        idx = self.letter_to_idx[letter]\n",
    "                        p = np.sum(alpha[-1] * self.emission_probs[:, idx])\n",
    "                        probs[letter] += p\n",
    "        \n",
    "        # Normalize probabilities\n",
    "        total = sum(probs.values())\n",
    "        if total > 0:\n",
    "            return {k: v/total for k, v in probs.items()}\n",
    "        return {k: 1.0/len(probs) for k in probs.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa9549",
   "metadata": {},
   "source": [
    "# 3. HMM Training and Evaluation\n",
    "\n",
    "Now let's train our HMM on the corpus and evaluate its performance. We'll:\n",
    "1. Train the model on a portion of the corpus\n",
    "2. Validate its predictions on a held-out set\n",
    "3. Visualize the learned letter probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1db79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1911a815904db1a135d948b1c06444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training HMM:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m correct_predictions / total_predictions \u001b[38;5;28;01mif\u001b[39;00m total_predictions > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Evaluate HMM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m accuracy = \u001b[43mevaluate_hmm_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHMM Prediction Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Visualize letter probabilities for a sample word\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mevaluate_hmm_predictions\u001b[39m\u001b[34m(hmm, words, n_samples)\u001b[39m\n\u001b[32m     22\u001b[39m partial_word = mask_word(word, guessed_letters)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Get HMM predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m probs = \u001b[43mhmm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_letter_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguessed_letters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m probs:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mHangmanHMM.get_letter_probabilities\u001b[39m\u001b[34m(self, partial_word, guessed_letters)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(partial_word)):\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emissions[pos] == -\u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m         alpha = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m         beta = \u001b[38;5;28mself\u001b[39m.backward_algorithm(emissions[pos+\u001b[32m1\u001b[39m:])\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# Compute distribution over possible letters\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mHangmanHMM.forward_algorithm\u001b[39m\u001b[34m(self, emissions)\u001b[39m\n\u001b[32m     27\u001b[39m alpha = np.zeros((T, \u001b[38;5;28mself\u001b[39m.n_states))\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Initialize first timestep\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m alpha[\u001b[32m0\u001b[39m] = \u001b[38;5;28mself\u001b[39m.initial_probs * \u001b[38;5;28mself\u001b[39m.emission_probs[:, \u001b[43memissions\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, T):\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Split corpus into train and validation sets\n",
    "np.random.shuffle(corpus)\n",
    "train_size = int(0.8 * len(corpus))\n",
    "train_words = corpus[:train_size]\n",
    "val_words = corpus[train_size:]\n",
    "\n",
    "# Initialize and train HMM\n",
    "hmm = HangmanHMM(n_states=10)\n",
    "hmm.train(train_words, n_iterations=50)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_hmm_predictions(hmm: HangmanHMM, words: List[str], n_samples: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate HMM's prediction accuracy on a set of words\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for word in random.sample(words, min(n_samples, len(words))):\n",
    "        # Create a random partial word\n",
    "        guessed_letters = set(random.sample(word, len(word)//2))\n",
    "        partial_word = mask_word(word, guessed_letters)\n",
    "        \n",
    "        # Get HMM predictions\n",
    "        probs = hmm.get_letter_probabilities(partial_word, guessed_letters)\n",
    "        if not probs:\n",
    "            continue\n",
    "            \n",
    "        # Check if the most likely predicted letter is in the word\n",
    "        predicted_letter = max(probs.items(), key=lambda x: x[1])[0]\n",
    "        correct_predictions += (predicted_letter in set(word) - guessed_letters)\n",
    "        total_predictions += 1\n",
    "    \n",
    "    return correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "# Evaluate HMM\n",
    "accuracy = evaluate_hmm_predictions(hmm, val_words)\n",
    "print(f\"HMM Prediction Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Visualize letter probabilities for a sample word\n",
    "sample_word = random.choice(val_words)\n",
    "guessed_letters = set(random.sample(sample_word, len(sample_word)//2))\n",
    "partial_word = mask_word(sample_word, guessed_letters)\n",
    "\n",
    "probs = hmm.get_letter_probabilities(partial_word, guessed_letters)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(probs.keys(), probs.values())\n",
    "plt.title(f'Letter Probabilities for Partial Word: {partial_word}')\n",
    "plt.xlabel('Letter')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "print(f\"True word: {sample_word}\")\n",
    "print(f\"Partial word: {partial_word}\")\n",
    "print(\"Top 5 predicted letters:\", sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f814a7e",
   "metadata": {},
   "source": [
    "# 4. Hangman Environment Implementation\n",
    "\n",
    "Now we'll implement the Hangman game environment that our RL agent will interact with. This environment will:\n",
    "1. Maintain game state (word, guessed letters, lives)\n",
    "2. Process actions (letter guesses)\n",
    "3. Calculate rewards\n",
    "4. Track game statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanEnv:\n",
    "    def __init__(self, word_list: List[str], hmm: HangmanHMM):\n",
    "        \"\"\"\n",
    "        Initialize Hangman environment\n",
    "        \n",
    "        Args:\n",
    "            word_list: List of possible words\n",
    "            hmm: Trained HMM model for letter predictions\n",
    "        \"\"\"\n",
    "        self.word_list = word_list\n",
    "        self.hmm = hmm\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Reset the environment for a new game\n",
    "        \n",
    "        Returns:\n",
    "            Initial state dictionary\n",
    "        \"\"\"\n",
    "        self.word = random.choice(self.word_list)\n",
    "        self.guessed_letters = set()\n",
    "        self.lives = MAX_WRONG_GUESSES\n",
    "        self.game_over = False\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def step(self, action: str) -> Tuple[Dict, float, bool, Dict]:\n",
    "        \"\"\"\n",
    "        Take an action (guess a letter) in the environment\n",
    "        \n",
    "        Args:\n",
    "            action: Letter to guess\n",
    "            \n",
    "        Returns:\n",
    "            (new_state, reward, done, info)\n",
    "        \"\"\"\n",
    "        if self.game_over or action in self.guessed_letters:\n",
    "            return self._get_state(), -2, True, {\"repeated_guess\": True}\n",
    "        \n",
    "        self.guessed_letters.add(action)\n",
    "        correct_guess = action in self.word\n",
    "        \n",
    "        # Update lives if guess was wrong\n",
    "        if not correct_guess:\n",
    "            self.lives -= 1\n",
    "        \n",
    "        # Check if game is over\n",
    "        current_word = mask_word(self.word, self.guessed_letters)\n",
    "        won = '_' not in current_word\n",
    "        lost = self.lives <= 0\n",
    "        self.game_over = won or lost\n",
    "        \n",
    "        # Calculate reward\n",
    "        if won:\n",
    "            reward = 10  # Big reward for winning\n",
    "        elif lost:\n",
    "            reward = -5  # Penalty for losing\n",
    "        elif correct_guess:\n",
    "            reward = 1   # Small reward for correct guess\n",
    "        else:\n",
    "            reward = -1  # Small penalty for wrong guess\n",
    "            \n",
    "        return self._get_state(), reward, self.game_over, {\n",
    "            \"won\": won,\n",
    "            \"lost\": lost,\n",
    "            \"lives\": self.lives,\n",
    "            \"word\": self.word if self.game_over else current_word\n",
    "        }\n",
    "    \n",
    "    def _get_state(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get current state representation\n",
    "        \"\"\"\n",
    "        current_word = mask_word(self.word, self.guessed_letters)\n",
    "        letter_probs = self.hmm.get_letter_probabilities(current_word, self.guessed_letters)\n",
    "        \n",
    "        return {\n",
    "            \"word_state\": current_word,\n",
    "            \"guessed_letters\": sorted(list(self.guessed_letters)),\n",
    "            \"lives\": self.lives,\n",
    "            \"letter_probs\": letter_probs\n",
    "        }\n",
    "    \n",
    "    def render(self) -> None:\n",
    "        \"\"\"\n",
    "        Display current game state\n",
    "        \"\"\"\n",
    "        current_word = mask_word(self.word, self.guessed_letters)\n",
    "        print(f\"\\nWord: {current_word}\")\n",
    "        print(f\"Lives: {self.lives}\")\n",
    "        print(f\"Guessed letters: {sorted(list(self.guessed_letters))}\")\n",
    "        if self.game_over:\n",
    "            print(f\"Game Over! Word was: {self.word}\")\n",
    "\n",
    "# Test the environment\n",
    "env = HangmanEnv(val_words, hmm)\n",
    "state = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Test a few random moves\n",
    "for _ in range(3):\n",
    "    available_letters = set(ALPHABET) - set(state[\"guessed_letters\"])\n",
    "    action = random.choice(list(available_letters))\n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f\"\\nAction: {action}, Reward: {reward}\")\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b49b1",
   "metadata": {},
   "source": [
    "# 5. RL Agent Implementation\n",
    "\n",
    "Now we'll implement our Reinforcement Learning agent using Deep Q-Learning. The agent will:\n",
    "1. Learn to choose optimal letters based on the current game state\n",
    "2. Use the HMM's letter probabilities as part of its state representation\n",
    "3. Balance exploration and exploitation using Îµ-greedy strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        \"\"\"\n",
    "        Deep Q-Network for Hangman\n",
    "        \n",
    "        Args:\n",
    "            input_size: Size of state representation\n",
    "            hidden_size: Size of hidden layers\n",
    "            output_size: Number of possible actions (26 letters)\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)\n",
    "\n",
    "class HangmanAgent:\n",
    "    def __init__(self, env: HangmanEnv, hidden_size: int = 128):\n",
    "        \"\"\"\n",
    "        Initialize Hangman RL agent\n",
    "        \n",
    "        Args:\n",
    "            env: Hangman environment\n",
    "            hidden_size: Size of hidden layers in DQN\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        \n",
    "        # State representation size: masked word one-hot (27) + guessed letters (26) + lives (1) + HMM probs (26)\n",
    "        self.state_size = 27 + 26 + 1 + 26\n",
    "        self.action_size = len(ALPHABET)\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.policy_net = DQN(self.state_size, hidden_size, self.action_size).to(DEVICE)\n",
    "        self.target_net = DQN(self.state_size, hidden_size, self.action_size).to(DEVICE)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters())\n",
    "        self.memory = []\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.99\n",
    "        self.eps_start = 1.0\n",
    "        self.eps_end = 0.01\n",
    "        self.eps_decay = 0.995\n",
    "        self.epsilon = self.eps_start\n",
    "        \n",
    "    def state_to_tensor(self, state: Dict) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert state dictionary to tensor representation\n",
    "        \"\"\"\n",
    "        # One-hot encode masked word\n",
    "        word_tensor = torch.zeros(27)  # 26 letters + '_'\n",
    "        for char in state[\"word_state\"]:\n",
    "            idx = self.letter_to_idx(char)\n",
    "            word_tensor[idx] = 1\n",
    "            \n",
    "        # One-hot encode guessed letters\n",
    "        guessed_tensor = torch.zeros(26)\n",
    "        for letter in state[\"guessed_letters\"]:\n",
    "            idx = self.letter_to_idx(letter)\n",
    "            guessed_tensor[idx] = 1\n",
    "            \n",
    "        # Normalize lives\n",
    "        lives_tensor = torch.tensor([state[\"lives\"] / MAX_WRONG_GUESSES])\n",
    "        \n",
    "        # HMM probabilities\n",
    "        hmm_tensor = torch.zeros(26)\n",
    "        for letter, prob in state[\"letter_probs\"].items():\n",
    "            idx = self.letter_to_idx(letter)\n",
    "            hmm_tensor[idx] = prob\n",
    "            \n",
    "        return torch.cat([word_tensor, guessed_tensor, lives_tensor, hmm_tensor]).to(DEVICE)\n",
    "    \n",
    "    @staticmethod\n",
    "    def letter_to_idx(letter: str) -> int:\n",
    "        \"\"\"Convert letter to index\"\"\"\n",
    "        if letter == '_':\n",
    "            return 26\n",
    "        return ord(letter) - ord('a')\n",
    "    \n",
    "    @staticmethod\n",
    "    def idx_to_letter(idx: int) -> str:\n",
    "        \"\"\"Convert index to letter\"\"\"\n",
    "        if idx == 26:\n",
    "            return '_'\n",
    "        return chr(idx + ord('a'))\n",
    "    \n",
    "    def select_action(self, state: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Select action using epsilon-greedy policy\n",
    "        \"\"\"\n",
    "        if random.random() > self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = self.state_to_tensor(state).unsqueeze(0)\n",
    "                q_values = self.policy_net(state_tensor)\n",
    "                \n",
    "                # Mask out guessed letters\n",
    "                mask = torch.ones_like(q_values)\n",
    "                for letter in state[\"guessed_letters\"]:\n",
    "                    idx = self.letter_to_idx(letter)\n",
    "                    mask[0, idx] = float('-inf')\n",
    "                \n",
    "                action_idx = torch.argmax(q_values + mask).item()\n",
    "                return self.idx_to_letter(action_idx)\n",
    "        else:\n",
    "            # Random action from unguessed letters\n",
    "            available = set(ALPHABET) - set(state[\"guessed_letters\"])\n",
    "            return random.choice(list(available))\n",
    "    \n",
    "    def train(self, n_episodes: int = 1000):\n",
    "        \"\"\"\n",
    "        Train the agent\n",
    "        \"\"\"\n",
    "        episode_rewards = []\n",
    "        win_rates = []\n",
    "        \n",
    "        for episode in tqdm(range(n_episodes), desc=\"Training\"):\n",
    "            state = self.env.reset()\n",
    "            total_reward = 0\n",
    "            \n",
    "            while True:\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done, info = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                \n",
    "                # Store transition\n",
    "                self.memory.append((state, action, reward, next_state, done))\n",
    "                \n",
    "                # Optimize model if enough samples\n",
    "                if len(self.memory) >= self.batch_size:\n",
    "                    self.optimize_model()\n",
    "                \n",
    "                state = next_state\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # Decay epsilon\n",
    "            self.epsilon = max(self.eps_end, self.epsilon * self.eps_decay)\n",
    "            \n",
    "            # Update statistics\n",
    "            episode_rewards.append(total_reward)\n",
    "            if (episode + 1) % 100 == 0:\n",
    "                win_rate = self.evaluate(100)\n",
    "                win_rates.append(win_rate)\n",
    "                \n",
    "                # Update target network\n",
    "                self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        return episode_rewards, win_rates\n",
    "    \n",
    "    def optimize_model(self):\n",
    "        \"\"\"\n",
    "        Perform one step of optimization\n",
    "        \"\"\"\n",
    "        # Sample batch\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        state_batch = torch.stack([self.state_to_tensor(s) for s, _, _, _, _ in batch])\n",
    "        action_batch = torch.tensor([[self.letter_to_idx(a)] for _, a, _, _, _ in batch], device=DEVICE)\n",
    "        reward_batch = torch.tensor([r for _, _, r, _, _ in batch], device=DEVICE)\n",
    "        next_state_batch = torch.stack([self.state_to_tensor(s) for _, _, _, s, _ in batch])\n",
    "        done_batch = torch.tensor([d for _, _, _, _, d in batch], device=DEVICE)\n",
    "        \n",
    "        # Compute Q values\n",
    "        current_q = self.policy_net(state_batch).gather(1, action_batch)\n",
    "        next_q = self.target_net(next_state_batch).max(1)[0].detach()\n",
    "        target_q = reward_batch + (1 - done_batch.float()) * self.gamma * next_q\n",
    "        \n",
    "        # Compute loss and optimize\n",
    "        loss = nn.MSELoss()(current_q.squeeze(), target_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def evaluate(self, n_games: int = 100) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate agent performance\n",
    "        \"\"\"\n",
    "        wins = 0\n",
    "        self.policy_net.eval()\n",
    "        \n",
    "        for _ in range(n_games):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                with torch.no_grad():\n",
    "                    action = self.select_action(state)\n",
    "                    state, _, done, info = self.env.step(action)\n",
    "                    if info.get(\"won\", False):\n",
    "                        wins += 1\n",
    "        \n",
    "        self.policy_net.train()\n",
    "        return wins / n_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5862937",
   "metadata": {},
   "source": [
    "# 6. Training Loop and Visualization\n",
    "\n",
    "Now we'll train our agent and visualize its learning progress. We'll track:\n",
    "1. Episode rewards\n",
    "2. Win rates\n",
    "3. Average mistakes per game\n",
    "4. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad168144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent and environment\n",
    "env = HangmanEnv(train_words, hmm)\n",
    "agent = HangmanAgent(env)\n",
    "\n",
    "# Train agent\n",
    "n_episodes = 2000\n",
    "episode_rewards, win_rates = agent.train(n_episodes)\n",
    "\n",
    "# Plot training progress\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot episode rewards\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(episode_rewards)\n",
    "plt.title('Episode Rewards Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "\n",
    "# Plot win rates\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(100, n_episodes + 1, 100), win_rates)\n",
    "plt.title('Win Rate Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Win Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "n_eval_games = 2000\n",
    "wins = 0\n",
    "total_wrong_guesses = 0\n",
    "total_repeated_guesses = 0\n",
    "\n",
    "for _ in tqdm(range(n_eval_games), desc=\"Evaluating\"):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    wrong_guesses = 0\n",
    "    repeated_guesses = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(state)\n",
    "        state, _, done, info = env.step(action)\n",
    "        \n",
    "        if info.get(\"repeated_guess\", False):\n",
    "            repeated_guesses += 1\n",
    "        elif not info.get(\"won\", False) and not info.get(\"lost\", False):\n",
    "            wrong_guesses += (info[\"lives\"] < env.lives)\n",
    "            \n",
    "        if info.get(\"won\", False):\n",
    "            wins += 1\n",
    "    \n",
    "    total_wrong_guesses += wrong_guesses\n",
    "    total_repeated_guesses += repeated_guesses\n",
    "\n",
    "success_rate = wins / n_eval_games\n",
    "final_score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
    "\n",
    "print(f\"Success Rate: {success_rate:.2%}\")\n",
    "print(f\"Average Wrong Guesses: {total_wrong_guesses / n_eval_games:.2f}\")\n",
    "print(f\"Average Repeated Guesses: {total_repeated_guesses / n_eval_games:.2f}\")\n",
    "print(f\"Final Score: {final_score:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "    'policy_net_state_dict': agent.policy_net.state_dict(),\n",
    "    'target_net_state_dict': agent.target_net.state_dict(),\n",
    "    'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "}, 'hangman_agent.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c312eb",
   "metadata": {},
   "source": [
    "# 7. Final Evaluation and Scoring\n",
    "\n",
    "Let's analyze the agent's performance on test games and visualize its decision-making process. We'll also demonstrate how the HMM and RL components work together to make intelligent guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a sample game to demonstrate the agent's decision making\n",
    "def play_demo_game(agent: HangmanAgent, word: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Play a demonstration game with detailed analysis of each move\n",
    "    \"\"\"\n",
    "    state = agent.env.reset()\n",
    "    if word:\n",
    "        agent.env.word = word\n",
    "        state = agent.env._get_state()\n",
    "    \n",
    "    print(f\"Starting new game. Word has {len(agent.env.word)} letters.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        # Show current state\n",
    "        print(f\"Current word: {state['word_state']}\")\n",
    "        print(f\"Lives remaining: {state['lives']}\")\n",
    "        print(f\"Guessed letters: {', '.join(sorted(state['guessed_letters']))}\")\n",
    "        \n",
    "        # Get HMM probabilities\n",
    "        hmm_probs = state['letter_probs']\n",
    "        top_hmm = sorted(hmm_probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(\"\\nHMM suggestions (top 5):\")\n",
    "        for letter, prob in top_hmm:\n",
    "            print(f\"{letter}: {prob:.3f}\")\n",
    "        \n",
    "        # Get agent's action\n",
    "        action = agent.select_action(state)\n",
    "        print(f\"\\nAgent chooses: {action}\")\n",
    "        \n",
    "        # Take action\n",
    "        state, reward, done, info = agent.env.step(action)\n",
    "        print(f\"Reward: {reward}\")\n",
    "        \n",
    "        if done:\n",
    "            print(\"\\nGame Over!\")\n",
    "            print(f\"Word was: {agent.env.word}\")\n",
    "            print(f\"Result: {'Won' if info.get('won', False) else 'Lost'}\")\n",
    "            break\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Play a few demonstration games\n",
    "print(\"Playing demonstration games...\\n\")\n",
    "for _ in range(3):\n",
    "    play_demo_game(agent)\n",
    "    print(\"\\n\" + \"#\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba924ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49979 words from corpus at C:\\Users\\aryan\\OneDrive\\Desktop\\ML_HACK\\Data\\Data\\corpus.txt\n",
      "\n",
      "Sample words from corpus:\n",
      "['distillatory', 'negroish', 'camata', 'rotundify', 'ramtil', 'samsonistic', 'transischiac', 'permutation', 'rechallenge', 'chromopsia']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus statistics:\n",
      "Total number of words: 49979\n",
      "Average word length: 9.50\n",
      "Min word length: 1\n",
      "Max word length: 24\n",
      "Number of unique word lengths: 24\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus file path\n",
    "CORPUS_PATH = r\"C:\\Users\\aryan\\OneDrive\\Desktop\\ML_HACK\\Data\\Data\\corpus.txt\"\n",
    "\n",
    "# Load the corpus\n",
    "corpus = load_corpus(CORPUS_PATH)\n",
    "print(f\"Loaded {len(corpus)} words from corpus at {CORPUS_PATH}\")\n",
    "\n",
    "# Display some statistics about the corpus\n",
    "print(\"\\nSample words from corpus:\")\n",
    "print(random.sample(corpus, 10))\n",
    "\n",
    "# Analyze word length distribution\n",
    "length_dist = get_word_length_distribution(corpus)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(length_dist.keys(), length_dist.values())\n",
    "plt.title('Word Length Distribution in Corpus')\n",
    "plt.xlabel('Word Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Basic corpus statistics\n",
    "print(f\"\\nCorpus statistics:\")\n",
    "print(f\"Total number of words: {len(corpus)}\")\n",
    "print(f\"Average word length: {sum(len(word) for word in corpus)/len(corpus):.2f}\")\n",
    "print(f\"Min word length: {min(len(word) for word in corpus)}\")\n",
    "print(f\"Max word length: {max(len(word) for word in corpus)}\")\n",
    "print(f\"Number of unique word lengths: {len(length_dist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea61ec9",
   "metadata": {},
   "source": [
    "# Hangman Environment Implementation\n",
    "\n",
    "Let's create a clean, well-documented implementation of the Hangman environment. This environment will:\n",
    "\n",
    "1. **State Space Design**\n",
    "   - Masked word (e.g., \"_ P P L _\")\n",
    "   - Set of guessed letters\n",
    "   - Number of lives remaining\n",
    "   - HMM probability distribution\n",
    "\n",
    "2. **Action Space**\n",
    "   - Any unguessed letter from A-Z\n",
    "   - Invalid actions: already guessed letters\n",
    "\n",
    "3. **Reward Structure**\n",
    "   - Winning: +10 (high reward for completing the word)\n",
    "   - Correct guess: +1 (small reward for progress)\n",
    "   - Wrong guess: -1 (small penalty)\n",
    "   - Losing: -5 (significant penalty)\n",
    "   - Repeated guess: -2 (penalty for inefficiency)\n",
    "\n",
    "4. **Termination Conditions**\n",
    "   - Word is completely revealed (Win)\n",
    "   - No lives remaining (Loss)\n",
    "   - Invalid action (Early termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Set, Dict, Tuple\n",
    "import random\n",
    "\n",
    "class HangmanEnvironment:\n",
    "    def __init__(self, word_list: List[str], max_lives: int = 6):\n",
    "        \"\"\"\n",
    "        Initialize Hangman Environment\n",
    "        \n",
    "        Args:\n",
    "            word_list: List of possible words for the game\n",
    "            max_lives: Maximum number of wrong guesses allowed\n",
    "        \"\"\"\n",
    "        self.word_list = word_list\n",
    "        self.max_lives = max_lives\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Reset the environment for a new game\n",
    "        \n",
    "        Returns:\n",
    "            dict: Initial state containing:\n",
    "                - word_state: The masked word (e.g., \"_ _ P L _\")\n",
    "                - guessed_letters: Set of letters already guessed\n",
    "                - lives: Number of lives remaining\n",
    "        \"\"\"\n",
    "        self.word = random.choice(self.word_list).lower()\n",
    "        self.guessed_letters = set()\n",
    "        self.lives = self.max_lives\n",
    "        self.done = False\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def step(self, action: str) -> Tuple[Dict, float, bool, Dict]:\n",
    "        \"\"\"\n",
    "        Take an action in the environment\n",
    "        \n",
    "        Args:\n",
    "            action: The letter to guess (must be lowercase a-z)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (new_state, reward, done, info)\n",
    "                - new_state: Current game state\n",
    "                - reward: Reward for the action\n",
    "                - done: Whether the episode is finished\n",
    "                - info: Additional information for debugging\n",
    "        \"\"\"\n",
    "        # Validate action\n",
    "        if not isinstance(action, str) or len(action) != 1 or action not in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            raise ValueError(\"Invalid action. Must be a single lowercase letter.\")\n",
    "            \n",
    "        # Check if game is already over\n",
    "        if self.done:\n",
    "            return self._get_state(), 0, True, {\"error\": \"Game already over\"}\n",
    "            \n",
    "        # Check if letter was already guessed\n",
    "        if action in self.guessed_letters:\n",
    "            return self._get_state(), -2, True, {\"error\": \"Letter already guessed\"}\n",
    "            \n",
    "        # Add letter to guessed letters\n",
    "        self.guessed_letters.add(action)\n",
    "        \n",
    "        # Check if guess is correct\n",
    "        correct_guess = action in self.word\n",
    "        \n",
    "        # Update lives if guess was wrong\n",
    "        if not correct_guess:\n",
    "            self.lives -= 1\n",
    "            \n",
    "        # Calculate current word state\n",
    "        current_state = self._get_masked_word()\n",
    "        \n",
    "        # Check win/loss conditions\n",
    "        won = '_' not in current_state\n",
    "        lost = self.lives <= 0\n",
    "        self.done = won or lost\n",
    "        \n",
    "        # Calculate reward\n",
    "        if won:\n",
    "            reward = 10  # Big reward for winning\n",
    "        elif lost:\n",
    "            reward = -5  # Penalty for losing\n",
    "        elif correct_guess:\n",
    "            reward = 1   # Small reward for correct guess\n",
    "        else:\n",
    "            reward = -1  # Small penalty for wrong guess\n",
    "            \n",
    "        info = {\n",
    "            \"won\": won,\n",
    "            \"lost\": lost,\n",
    "            \"lives_remaining\": self.lives,\n",
    "            \"word\": self.word if self.done else current_state\n",
    "        }\n",
    "        \n",
    "        return self._get_state(), reward, self.done, info\n",
    "    \n",
    "    def _get_masked_word(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the current state of the word with unguessed letters masked\n",
    "        \n",
    "        Returns:\n",
    "            str: The word with unguessed letters replaced by '_'\n",
    "        \"\"\"\n",
    "        return ''.join(letter if letter in self.guessed_letters else '_' \n",
    "                      for letter in self.word)\n",
    "    \n",
    "    def _get_state(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get the current state of the environment\n",
    "        \n",
    "        Returns:\n",
    "            dict: Current state information\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"word_state\": self._get_masked_word(),\n",
    "            \"guessed_letters\": self.guessed_letters.copy(),\n",
    "            \"lives\": self.lives\n",
    "        }\n",
    "    \n",
    "    def render(self) -> None:\n",
    "        \"\"\"\n",
    "        Display the current state of the game\n",
    "        \"\"\"\n",
    "        print(\"\\nCurrent Game State:\")\n",
    "        print(f\"Word: {self._get_masked_word()}\")\n",
    "        print(f\"Lives: {self.lives}\")\n",
    "        print(f\"Guessed letters: {sorted(list(self.guessed_letters))}\")\n",
    "        if self.done:\n",
    "            print(f\"Game Over! Word was: {self.word}\")\n",
    "            \n",
    "    @property\n",
    "    def action_space(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get the current valid actions (unguessed letters)\n",
    "        \"\"\"\n",
    "        return [letter for letter in 'abcdefghijklmnopqrstuvwxyz' \n",
    "                if letter not in self.guessed_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fafc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the environment with some random games\n",
    "def play_random_game(env: HangmanEnvironment):\n",
    "    \"\"\"Play a random game of Hangman\"\"\"\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    print(\"\\nStarting new game...\")\n",
    "    env.render()\n",
    "    \n",
    "    while True:\n",
    "        # Choose random action from available actions\n",
    "        action = random.choice(env.action_space)\n",
    "        print(f\"\\nGuessing letter: {action}\")\n",
    "        \n",
    "        # Take step in environment\n",
    "        state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Display results\n",
    "        env.render()\n",
    "        print(f\"Reward: {reward}\")\n",
    "        \n",
    "        if done:\n",
    "            print(f\"\\nGame Over! Total Reward: {total_reward}\")\n",
    "            if info.get(\"won\", False):\n",
    "                print(\"Result: Won! ð\")\n",
    "            else:\n",
    "                print(\"Result: Lost ð¢\")\n",
    "            break\n",
    "\n",
    "# Play 3 random games to test the environment\n",
    "print(\"Testing Hangman Environment with Random Games\")\n",
    "env = HangmanEnvironment(word_list=corpus[:1000])  # Use first 1000 words for testing\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\n{'='*50}\\nGame {i+1}\")\n",
    "    play_random_game(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88641ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated HMM implementation with improved handling of edge cases\n",
    "class HangmanHMM:\n",
    "    def __init__(self, n_states: int = 10):\n",
    "        self.n_states = n_states\n",
    "        self.n_emissions = len(ALPHABET)\n",
    "        self.letter_to_idx = {letter: idx for idx, letter in enumerate(ALPHABET)}\n",
    "        \n",
    "        # Initialize model parameters with smoothing\n",
    "        self.transition_probs = np.ones((n_states, n_states)) / n_states\n",
    "        self.emission_probs = np.ones((n_states, self.n_emissions)) / self.n_emissions\n",
    "        self.initial_probs = np.ones(n_states) / n_states\n",
    "        \n",
    "    def _prepare_sequence(self, word: str) -> np.ndarray:\n",
    "        return np.array([self.letter_to_idx[c] for c in word])\n",
    "    \n",
    "    def forward_algorithm(self, emissions: np.ndarray) -> np.ndarray:\n",
    "        if len(emissions) == 0:\n",
    "            return np.ones((1, self.n_states)) / self.n_states\n",
    "        \n",
    "        T = len(emissions)\n",
    "        alpha = np.zeros((T, self.n_states))\n",
    "        \n",
    "        # Initialize with smoothing\n",
    "        alpha[0] = self.initial_probs * self.emission_probs[:, emissions[0]]\n",
    "        alpha[0] = alpha[0] / (alpha[0].sum() + 1e-10)\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            for s in range(self.n_states):\n",
    "                alpha[t, s] = self.emission_probs[s, emissions[t]] * np.sum(\n",
    "                    alpha[t-1] * self.transition_probs[:, s])\n",
    "            alpha[t] = alpha[t] / (alpha[t].sum() + 1e-10)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def backward_algorithm(self, emissions: np.ndarray) -> np.ndarray:\n",
    "        if len(emissions) == 0:\n",
    "            return np.ones((1, self.n_states)) / self.n_states\n",
    "        \n",
    "        T = len(emissions)\n",
    "        beta = np.zeros((T, self.n_states))\n",
    "        beta[-1] = 1\n",
    "        beta[-1] = beta[-1] / (beta[-1].sum() + 1e-10)\n",
    "        \n",
    "        for t in range(T-2, -1, -1):\n",
    "            for s in range(self.n_states):\n",
    "                beta[t, s] = np.sum(\n",
    "                    beta[t+1] * self.transition_probs[s, :] * \n",
    "                    self.emission_probs[:, emissions[t+1]])\n",
    "            beta[t] = beta[t] / (beta[t].sum() + 1e-10)\n",
    "        \n",
    "        return beta\n",
    "    \n",
    "    def train(self, words: List[str], n_iterations: int = 100):\n",
    "        for _ in tqdm(range(n_iterations), desc=\"Training HMM\"):\n",
    "            trans_counts = np.zeros_like(self.transition_probs)\n",
    "            emit_counts = np.zeros_like(self.emission_probs)\n",
    "            init_counts = np.zeros_like(self.initial_probs)\n",
    "            \n",
    "            for word in words:\n",
    "                emissions = self._prepare_sequence(word)\n",
    "                if len(emissions) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                alpha = self.forward_algorithm(emissions)\n",
    "                beta = self.backward_algorithm(emissions)\n",
    "                \n",
    "                gamma = alpha * beta\n",
    "                gamma = gamma / (gamma.sum(axis=1, keepdims=True) + 1e-10)\n",
    "                \n",
    "                init_counts += gamma[0]\n",
    "                for t in range(len(emissions)-1):\n",
    "                    trans_counts += np.outer(gamma[t], gamma[t+1])\n",
    "                for t in range(len(emissions)):\n",
    "                    emit_counts[:, emissions[t]] += gamma[t]\n",
    "            \n",
    "            # Update parameters with smoothing\n",
    "            smooth = 1e-10\n",
    "            self.initial_probs = (init_counts + smooth) / (init_counts.sum() + smooth * self.n_states)\n",
    "            self.transition_probs = (trans_counts + smooth) / (trans_counts.sum(axis=1, keepdims=True) + smooth * self.n_states)\n",
    "            self.emission_probs = (emit_counts + smooth) / (emit_counts.sum(axis=1, keepdims=True) + smooth * self.n_emissions)\n",
    "    \n",
    "    def get_letter_probabilities(self, partial_word: str, guessed_letters: Set[str]) -> Dict[str, float]:\n",
    "        emissions = []\n",
    "        for c in partial_word:\n",
    "            if c == '_':\n",
    "                emissions.append(-1)\n",
    "            else:\n",
    "                emissions.append(self.letter_to_idx[c])\n",
    "        emissions = np.array(emissions)\n",
    "        \n",
    "        probs = defaultdict(float)\n",
    "        for pos in range(len(partial_word)):\n",
    "            if emissions[pos] == -1:\n",
    "                prefix = emissions[:pos] if pos > 0 else np.array([])\n",
    "                suffix = emissions[pos+1:] if pos < len(emissions)-1 else np.array([])\n",
    "                \n",
    "                alpha = self.forward_algorithm(prefix)\n",
    "                beta = self.backward_algorithm(suffix)\n",
    "                \n",
    "                for letter in ALPHABET:\n",
    "                    if letter not in guessed_letters:\n",
    "                        idx = self.letter_to_idx[letter]\n",
    "                        if len(prefix) == 0:\n",
    "                            p = np.mean(self.emission_probs[:, idx])  # Use mean emission probability for first position\n",
    "                        else:\n",
    "                            p = np.sum(alpha[-1] * self.emission_probs[:, idx])\n",
    "                        probs[letter] += p\n",
    "        \n",
    "        if not probs:  # If no probabilities were calculated\n",
    "            available_letters = set(ALPHABET) - guessed_letters\n",
    "            return {letter: 1.0/len(available_letters) for letter in available_letters}\n",
    "        \n",
    "        total = sum(probs.values()) + 1e-10\n",
    "        return {k: v/total for k, v in probs.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
