{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4a51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import config\n",
    "import utils\n",
    "from hmm_model import HangmanHMM\n",
    "from hangman_env import HangmanEnv\n",
    "from rl_agent import HangmanAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859496e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49979 valid words from corpus.txt.\n",
      "Loading trained HMM...\n",
      "HMM model loaded from hmm_model.pkl\n",
      "Loading trained RL Agent...\n"
     ]
    }
   ],
   "source": [
    "# Load corpus\n",
    "corpus = utils.load_corpus(config.CORPUS_PATH)\n",
    "\n",
    "# Load the trained HMM\n",
    "print(\"Loading trained HMM...\")\n",
    "hmm = HangmanHMM.load(config.HMM_MODEL_PATH)\n",
    "\n",
    "# Initialize the Environment\n",
    "env = HangmanEnv(corpus)\n",
    "\n",
    "# Initialize the Agent\n",
    "print(\"Loading trained RL Agent...\")\n",
    "agent = HangmanAgent(config.STATE_SIZE, config.ACTION_SIZE)\n",
    "\n",
    "# Load the *trained weights* into the agent's network\n",
    "agent.q_network.load_state_dict(torch.load(config.AGENT_MODEL_PATH))\n",
    "\n",
    "# ‚ö†Ô∏è CRITICAL: Set the agent to evaluation mode\n",
    "agent.q_network.eval()\n",
    "agent.epsilon = 0.0  # No more exploration, only exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b895e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final evaluation for 2000 games...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d26fbd07064296ac84f5909914b2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation finished in 0.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running final evaluation for {config.NUM_EPISODES_EVAL} games...\")\n",
    "\n",
    "total_wins = 0\n",
    "total_wrong_guesses = 0\n",
    "total_repeated_guesses = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for episode in tqdm(range(config.NUM_EPISODES_EVAL)):\n",
    "    env_state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    episode_wrong_guesses = 0\n",
    "    episode_repeated_guesses = 0\n",
    "    \n",
    "    while not done:\n",
    "        # 1. Get HMM probabilities\n",
    "        hmm_probs = hmm.get_letter_probabilities(\n",
    "            env_state['masked_word'], \n",
    "            env_state['guessed_letters']\n",
    "        )\n",
    "        \n",
    "        # 2. Get state vector\n",
    "        state_vec = agent.state_to_vector(env_state, hmm_probs)\n",
    "        \n",
    "        # 3. Select *best* action (no exploration)\n",
    "        action_idx = agent.select_action(state_vec, env_state['guessed_letters'])\n",
    "        action_letter = config.ALPHABET[action_idx]\n",
    "        \n",
    "        # 4. Step environment\n",
    "        next_env_state, reward, done, info = env.step(action_letter)\n",
    "        \n",
    "        # 5. Track stats\n",
    "        if info.get('wrong_guess'):\n",
    "            episode_wrong_guesses += 1\n",
    "        if info.get('repeated_guess'):\n",
    "            episode_repeated_guesses += 1\n",
    "        \n",
    "        if done:\n",
    "            if info.get('win'):\n",
    "                total_wins += 1\n",
    "        \n",
    "        env_state = next_env_state\n",
    "    \n",
    "    # Add episode stats to totals\n",
    "    total_wrong_guesses += episode_wrong_guesses\n",
    "    total_repeated_guesses += episode_repeated_guesses\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nEvaluation finished in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425276d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " ü§ñ HACKMAN AGENT FINAL REPORT ü§ñ\n",
      "==============================\n",
      "Total Games Played: 2000\n",
      "\n",
      "--- PERFORMANCE ---\n",
      "Success Rate:         7.70%  (154 wins)\n",
      "Avg. Wrong Guesses:   5.84\n",
      "Avg. Repeated Guesses: 0.00\n",
      "\n",
      "--- RAW COUNTS ---\n",
      "Total Wrong Guesses:    11689\n",
      "Total Repeated Guesses: 0\n",
      "\n",
      "--- SCORING ---\n",
      "Success Bonus:          +154\n",
      "Wrong Guess Penalty:    -58445\n",
      "Repeated Guess Penalty: -0\n",
      "-----------------------------------\n",
      "üèÜ FINAL SCORE:          -58291.00 üèÜ\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Final Metrics ---\n",
    "success_rate = total_wins / config.NUM_EPISODES_EVAL\n",
    "avg_wrong_guesses = total_wrong_guesses / config.NUM_EPISODES_EVAL\n",
    "avg_repeated_guesses = total_repeated_guesses / config.NUM_EPISODES_EVAL\n",
    "\n",
    "# --- Calculate Final Score (from problem statement) ---\n",
    "# Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
    "final_score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
    "\n",
    "# --- Print Final Report ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\" ü§ñ HACKMAN AGENT FINAL REPORT ü§ñ\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Total Games Played: {config.NUM_EPISODES_EVAL}\")\n",
    "print(\"\\n--- PERFORMANCE ---\")\n",
    "print(f\"Success Rate:         {success_rate * 100:.2f}%  ({total_wins} wins)\")\n",
    "print(f\"Avg. Wrong Guesses:   {avg_wrong_guesses:.2f}\")\n",
    "print(f\"Avg. Repeated Guesses: {avg_repeated_guesses:.2f}\")\n",
    "\n",
    "print(\"\\n--- RAW COUNTS ---\")\n",
    "print(f\"Total Wrong Guesses:    {total_wrong_guesses}\")\n",
    "print(f\"Total Repeated Guesses: {total_repeated_guesses}\")\n",
    "\n",
    "print(\"\\n--- SCORING ---\")\n",
    "print(f\"Success Bonus:          +{(success_rate * 2000):.0f}\")\n",
    "print(f\"Wrong Guess Penalty:    -{(total_wrong_guesses * 5):.0f}\")\n",
    "print(f\"Repeated Guess Penalty: -{(total_repeated_guesses * 2):.0f}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"üèÜ FINAL SCORE:          {final_score:.2f} üèÜ\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b13f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
